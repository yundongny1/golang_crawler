This is the repository for crawling and scraping wikipedia pages in Go. Using the Colly package, it is relatively simple to write a script to scrape the web.

To start with this, we create a struct to hold the information we retrieve from webpage. This program only brings in the site URL and the entire body text, but depending on one's needs, you can even scrape the imgURL or any other specific information you want to scrape using HTML and CSS.Because we are using Colly, we create a collector using Colly. Using this collector, we can call on other functions such as onHTML, which is the actual function that we can specify the CSS element we want to scrape from the websites we are visitng. We append whatever result we get into a slice, and using a for loop, visit the list of webpages we defined in our urls slice.

The run time for this program is 1.1218s, compared to the Python Scraper which takes 10.7523 seconds to execute. While this program is much more simpler than Python's because it does not output the html files that the Python program does, most of the comile time actually comes from the crawling and scraping, which means Golang is superior to Python in terms of scraping due to its concurrency features.